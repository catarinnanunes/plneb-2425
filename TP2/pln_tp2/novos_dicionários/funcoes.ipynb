{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89766b5f",
   "metadata": {},
   "source": [
    "**Dicionário catalão COVID**: \n",
    "\n",
    "Passar as termos chave para os termos em português\n",
    "\n",
    "Ficheiro de saída: dicionario_medico_covid_pt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55104124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: A chave 'incapacidade' já existe. As informações serão combinadas.\n",
      "Aviso: A chave 'RAV' já existe. As informações serão combinadas.\n",
      "Aviso: A chave 'semiologia' já existe. As informações serão combinadas.\n",
      "Aviso: A chave 'CVnCoV' já existe. As informações serão combinadas.\n",
      "Transformação concluída. Arquivo salvo como 'dicionario_medico_covid_pt.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Carregar o JSON catalão\n",
    "with open(\"../dici_covid_corrigido/dicionario_covid_corrigido.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dados = json.load(f)\n",
    "\n",
    "novos_dados = {}\n",
    "\n",
    "for termo_original, info in dados.items():\n",
    "    traducoes = info.get(\"Traduções\", {})\n",
    "    termo_pt = None\n",
    "\n",
    "    # Verifica se há uma tradução em pt_PT com prioridade (porque pode haver pt_PT e pt na mesma entrada)\n",
    "    if \"pt_PT\" in traducoes:\n",
    "        termo_pt = traducoes[\"pt_PT\"][0]\n",
    "    elif \"pt\" in traducoes and \"pt_PT\" not in traducoes:\n",
    "        termo_pt = traducoes[\"pt\"][0]\n",
    "\n",
    "    if termo_pt:\n",
    "        nova_chave = termo_pt\n",
    "\n",
    "        # Clona a entrada\n",
    "        nova_entrada = info.copy()\n",
    "\n",
    "        # Atualiza traduções\n",
    "        novas_traducoes = nova_entrada.get(\"Traduções\", {}).copy()\n",
    "        novas_traducoes.pop(\"pt\", None)\n",
    "        novas_traducoes.pop(\"pt_PT\", None)\n",
    "        novas_traducoes[\"ca\"] = [termo_original]\n",
    "        nova_entrada[\"Traduções\"] = novas_traducoes\n",
    "\n",
    "        # Se já existe uma entrada com a nova chave, mesclar os dados\n",
    "        if nova_chave in novos_dados:\n",
    "            print(f\"Aviso: A chave '{nova_chave}' já existe. As informações serão combinadas.\")\n",
    "            entrada_existente = novos_dados[nova_chave]\n",
    "\n",
    "            entrada_fundida = {}\n",
    "\n",
    "            for campo in set(entrada_existente) | set(nova_entrada):\n",
    "                val1 = entrada_existente.get(campo)\n",
    "                val2 = nova_entrada.get(campo)\n",
    "\n",
    "                if isinstance(val1, list) and isinstance(val2, list):\n",
    "                    entrada_fundida[campo] = list(set(val1 + val2))\n",
    "                elif isinstance(val1, dict) and isinstance(val2, dict):\n",
    "                    fundido = {}\n",
    "                    for k in set(val1) | set(val2):\n",
    "                        v1 = val1.get(k, [])\n",
    "                        v2 = val2.get(k, [])\n",
    "                        if isinstance(v1, list) and isinstance(v2, list):\n",
    "                            fundido[k] = list(set(v1 + v2))\n",
    "                        else:\n",
    "                            fundido[k] = v2 or v1\n",
    "                    entrada_fundida[campo] = fundido\n",
    "                else:\n",
    "                    entrada_fundida[campo] = val2 if val2 is not None else val1\n",
    "\n",
    "            novos_dados[nova_chave] = entrada_fundida\n",
    "        else:\n",
    "            novos_dados[nova_chave] = nova_entrada\n",
    "    else:\n",
    "        # Se não há tradução em pt, mantém com o termo original\n",
    "        novos_dados[termo_original] = info\n",
    "\n",
    "# Salvar\n",
    "with open(\"dicionarios_originais/dicionario_medico_covid_pt.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(novos_dados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Transformação concluída. Arquivo salvo como 'dicionario_medico_covid_pt.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e8ec3",
   "metadata": {},
   "source": [
    "**Juntar de novo todos os ficheiros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "300e560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Função para carregar ficheiros\n",
    "def load_json(caminho):\n",
    "    with open(caminho, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Função básica para fundir dois valores\n",
    "def merge(v1, v2):\n",
    "    if type(v1) == dict and type(v2) == dict:\n",
    "        resultado = {}\n",
    "        for chave in set(list(v1.keys()) + list(v2.keys())):\n",
    "            if chave in v1 and chave in v2:\n",
    "                resultado[chave] = merge(v1[chave], v2[chave])\n",
    "            elif chave in v1:\n",
    "                resultado[chave] = v1[chave]\n",
    "            else:\n",
    "                resultado[chave] = v2[chave]\n",
    "        return resultado\n",
    "    \n",
    "    elif type(v1) == list and type(v2) == list:\n",
    "        return list(set(v1 + v2))\n",
    "    \n",
    "    elif type(v1) == str and type(v2) == str:\n",
    "        if v1 == v2:\n",
    "            return v1\n",
    "        else:\n",
    "            return list(set([v1, v2]))\n",
    "    \n",
    "    elif type(v1) == list:\n",
    "        return list(set(v1 + [v2]))\n",
    "    \n",
    "    elif type(v2) == list:\n",
    "        return list(set([v1] + v2))\n",
    "    \n",
    "    else:\n",
    "        return list(set([v1, v2]))\n",
    "\n",
    "# Carregamento dos dicionários\n",
    "d1 = load_json(\"dicionarios_originais/dicionario_medico_covid_pt.json\")\n",
    "d2 = load_json(\"dicionarios_originais/glossario.json\")\n",
    "d3 = load_json(\"dicionarios_originais/termos_medicos_populares.json\")\n",
    "d4 = load_json(\"dicionarios_originais/monitoramento-e-avaliacao-glossario.json\")\n",
    "\n",
    "# Lista com todos os dicionários\n",
    "todos = [d1, d2, d3, d4]\n",
    "\n",
    "# Dicionário final\n",
    "unificado = {}\n",
    "\n",
    "for dicionario in todos:\n",
    "    for termo in dicionario:\n",
    "        if termo not in unificado:\n",
    "            unificado[termo] = dicionario[termo]\n",
    "        else:\n",
    "            unificado[termo] = merge(unificado[termo], dicionario[termo])\n",
    "\n",
    "# Guardar o resultado final\n",
    "with open(\"dicionario_final_pt.json\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(unificado, f_out, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61ac90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de termos no dicionário da TP1: 3085\n",
      "Total de termos no dicionário novo pt: 3035\n"
     ]
    }
   ],
   "source": [
    "d_TP1 = load_json(\"dicionarios_originais/dicionario_final.json\")\n",
    "d_novo = load_json(\"dicionario_final_pt.json\")\n",
    "\n",
    "print (f\"Total de termos no dicionário da TP1: {len(d_TP1)}\")\n",
    "print(f\"Total de termos no dicionário novo pt: {len(d_novo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696b6b9",
   "metadata": {},
   "source": [
    "Extrair termos de um site sobre a covid: https://www.jpn.up.pt/2020/04/07/covid-19-as-palavras-que-entraram-no-nosso-vocabulario/\n",
    "\n",
    "dicionario_atualizado1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22c6da95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração concluída. Resultados salvos em 'covid_glossary.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "# URL da página (substitua pela URL real, caso esteja acessando diretamente)\n",
    "url = \"https://www.jpn.up.pt/2020/04/07/covid-19-as-palavras-que-entraram-no-nosso-vocabulario/\"  # Insira a URL real da página aqui\n",
    "\n",
    "# Função para limpar texto removendo quebras de linha e espaços extras\n",
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip())\n",
    "\n",
    "# Fazer a requisição HTTP para obter o conteúdo da página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Encontrar a seção com a classe 'post-content'\n",
    "post_content = soup.find('section', class_='post-content')\n",
    "\n",
    "# Lista para armazenar os resultados\n",
    "glossary = []\n",
    "\n",
    "# Encontrar todas as listas <ul> dentro da seção\n",
    "ul_elements = post_content.find_all('ul')\n",
    "\n",
    "for ul in ul_elements:\n",
    "    # Encontrar todos os itens <li> dentro de cada <ul>\n",
    "    li_elements = ul.find_all('li')\n",
    "    for li in li_elements:\n",
    "        # Extrair o termo, que está em <strong> ou <em><strong>\n",
    "        strong = li.find('strong')\n",
    "        if strong:\n",
    "            term = clean_text(strong.get_text())\n",
    "            # Extrair a definição, que está em <em> após o termo\n",
    "            em = li.find('em')\n",
    "            definition = clean_text(em.get_text()) if em else ''\n",
    "            # Extrair o texto relacionado, que é o conteúdo após o <em> ou todo o texto do <li>\n",
    "            related_text = clean_text(li.get_text().replace(strong.get_text(), '').replace(em.get_text() if em else '', ''))\n",
    "            glossary.append({\n",
    "                'term': term,\n",
    "                'definition': definition,\n",
    "                'related_text': related_text\n",
    "            })\n",
    "\n",
    "# Salvar os resultados em um arquivo JSON\n",
    "os.makedirs('dicionarios_scrapping', exist_ok=True)\n",
    "with open('dicionarios_scrapping/covid_glossary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(glossary, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Extração concluída. Resultados salvos em 'covid_glossary.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9625c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos em comum encontrados:\n",
      "quarentena\n",
      "\n",
      "fase de mitigação\n",
      "\n",
      "ventilador\n",
      "\n",
      "pandemia\n",
      "\n",
      "sintomatologia\n",
      "\n",
      "imunidade comunitária\n",
      "\n",
      "coronavírus\n",
      "\n",
      "teletrabalho\n",
      "\n",
      "zaragatoa\n",
      "\n",
      "viseira\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carregar os dados\n",
    "with open(\"dicionario_final_pt.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    termos_convertidos = json.load(f)\n",
    "\n",
    "with open(\"dicionarios_scrapping/covid_glossary.json\", \"r\", encoding=\"utf-8\") as f_covid_pt:\n",
    "    glossary_covid_pt = json.load(f_covid_pt)\n",
    "\n",
    "# Extrair os termos do glossário e converter para minúsculas\n",
    "glossary_terms_covid = {item[\"term\"].lower() for item in glossary_covid_pt}\n",
    "\n",
    "# Extrair os termos do outro dicionário (já são as chaves)\n",
    "other_terms = {term.lower() for term in termos_convertidos.keys()}\n",
    "\n",
    "# Encontrar termos em comum\n",
    "common_terms = glossary_terms_covid.intersection(other_terms)\n",
    "\n",
    "# Exibir os termos em comum e detalhes\n",
    "if common_terms:\n",
    "    print(\"Termos em comum encontrados:\")\n",
    "    for term in common_terms:\n",
    "        # Buscar os dados originais no glossário\n",
    "        for item in glossary_covid_pt:\n",
    "            if item[\"term\"].lower() == term:\n",
    "                \n",
    "                print(f\"{term}\")\n",
    "                # print(f\"Definição (do web scraping): {item.get('definition', 'N/A')}\")\n",
    "                # print(f\"Texto Relacionado (do web scraping): {item.get('related_text', 'N/A')}\")\n",
    "                # print(f\"Dados no outro dicionário: {termos_convertidos.get(term, 'N/A')}\")\n",
    "                # print(\"-\" * 50)\n",
    "        print()\n",
    "else:\n",
    "    print(\"Nenhum termo em comum encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7f782df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atualização concluída. Ficheiro salvo como 'dicionario_atualizado1.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carregar os dados\n",
    "with open(\"dicionario_final_pt.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dicionario_pt = json.load(f)\n",
    "\n",
    "with open(\"dicionarios_scrapping/covid_glossary.json\", \"r\", encoding=\"utf-8\") as f_covid_pt:\n",
    "    glossary_covid_pt = json.load(f_covid_pt)\n",
    "\n",
    "# Criar um dicionário de termos do glossário para acesso rápido\n",
    "glossary_dict = {\n",
    "    item[\"term\"].lower(): item for item in glossary_covid_pt\n",
    "}\n",
    "\n",
    "dicionario_pt_lower = {k.lower(): k for k in dicionario_pt}\n",
    "\n",
    "# Atualizar os termos existentes e adicionar os novos\n",
    "for termo_lower, item in glossary_dict.items():\n",
    "    descricao_completa = f\"{item.get('definition', '').strip()} {item.get('related_text', '').strip()}\"\n",
    "    \n",
    "    if termo_lower in dicionario_pt_lower:\n",
    "        termo_chave = dicionario_pt_lower[termo_lower]\n",
    "        dicionario_pt[termo_chave][\"descricao_pt\"] = descricao_completa\n",
    "    else:\n",
    "        dicionario_pt[item[\"term\"]] = {\n",
    "            \"descricao_pt\": descricao_completa\n",
    "        }\n",
    "\n",
    "# Gravar em novo ficheiro para preservar o original\n",
    "os.makedirs(\"dicionarios_atualizados\", exist_ok=True)\n",
    "with open(\"dicionarios_atualizados/dicionario_atualizado1.json\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(dicionario_pt, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Atualização concluída. Ficheiro salvo como 'dicionario_atualizado1.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c25dc14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de entradas no glossario atualizado1: 3053\n"
     ]
    }
   ],
   "source": [
    "with open(\"dicionarios_atualizados/dicionario_atualizado1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dicionario1 = json.load(f)\n",
    "print(f\"Total de entradas no glossario atualizado1: {len(dicionario1)}\") \n",
    "\n",
    "# with open(\"dicionarios_atualizados/dicionario_atualizado11.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     dicionario11 = json.load(f)\n",
    "# print(f\"Total de entradas no glossario atualizado11: {len(dicionario11)}\")\n",
    "\n",
    "# 3035 -> 3053"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
